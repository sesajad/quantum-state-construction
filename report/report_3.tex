\documentclass{article}

\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}

%\usepackage{amsmath}
\usepackage[arrowdel]{physics}
\usepackage{amsfonts}
\usepackage{amsthm}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\est}{Est}
\def\ind{\hspace{\parindent}}
\title{Brief Report}
\author{Amirreza Negari, Amirhossein Estiri, Sajad Kahani}
\date{Augest 2019}
\begin{document}

\maketitle

\section{Optimization Problem}
let ${\lambda_1\dots\lambda_m}$ be set of free degrees of Hamiltonian, $\ket{\phi_0}$ the ground state and $\ket{\psi}$ the target state.

formally, the problem can be formulated by this equation
\[ H^*(\lambda_1\dots\lambda_m), t^* = \argmax_{\lambda_1..\lambda_m, t} \mathcal{F}(e^{iH(\lambda_1\dots\lambda_m)t} \ket{\phi_0}, \ket{\psi}) \]

where $\mathcal{F}(., .)$ is fidelity.

specifically, we are focusing on a Hisenberg model, therefore

\[ H(J_1\dots J_{N-1}, B_1\dots B_N) = \sum_{i=1}^{N-1} J_i (X_i X_{i+1} + Y_i Y_{i+1}) + \sum_{i=1}^N B_i (1 - Z_i) \]

In this case, by multiplying each degrees by $\alpha$, and dividing $t$ by $\alpha$ result remains the same, therefore we can substitute $t$ with $t_0$.

\begin{equation} 
\label{eq:opt}
H^*(J_1\dots J_{N-1}, B_1\dots B_N) = \argmax_{J_1\dots J_{N-1}, B_1\dots B_N} \mathcal{F}(e^{iHt_0} \ket{\phi_0}, \ket{\psi})
\end{equation}


\section{Minimum Guaranteed Fidelity}

for any method for estimating states (that estimates $\ket{\phi}$ with $\est[\ket{\phi}]$, we can define a ``minimum guaranteed fidelity" (MGF) that

\[ \mathcal{F}(\ket{\phi}, \est[\ket{\phi}]) \ge \text{MGF} \]

in order to find MGF empirically, 
we define a mapping $f: \mathbb{R}^{2N} \rightarrow \mathcal{H}$ with $\dim \mathcal{H} = N$ as 
\[ f(\va{v}) := \sum_{i=1}^N (v_{2i} + iv_{2i+1}) \ket{i}\]

\newtheorem{lemma}{Lemma}
\begin{lemma}
for two arbitrary vectors $\va{v}$ and $\va{v'}$ in $\mathbb{R}^{2N}$
\[ \mathcal{F}(f(\va{v}), f(\va{v'})) \ge \va{v}\cdot\va{v'} \]
\end{lemma}

now we choose a set of $k$ equidistributed points on a 2N-d unit hypersphere called $P$.

for an arbitrary point $\va{x}$ on sphere, exists $\va{t} \in P$ that $\forall \va{p} \in P - \{\va{t}\} ~~ \va{t}\cdot\va{x} > \va{t}\cdot \va{p}$

then by mapping to hilbert space
\[ S := \{ f(\va{p}) ~|~ \va{p} \in P \} \]
\[ d := \min_{\va{x} \in P} ~\max_{\va{y} \in P - \{\va{x}\}} \va{x}\cdot\va{y} \]
\[ \forall \ket{\phi} \in \mathcal{H} ~~ \exists \ket{t} \in S ~~ \mathcal{F}(\ket{\phi}, \ket{t}) \ge d \]

We know from Fubini-Study metric that for three arbitrary states $\ket{a}$, $\ket{b}$ and $\ket{c}$
\[ \arccos\sqrt{\mathcal{F}(\ket{a},\ket{c})} \ge \arccos\sqrt{\mathcal{F}(\ket{a},\ket{b})} + \arccos\sqrt{\mathcal{F}(\ket{b},\ket{c})}  \]

now defining these
\[ E_{\mathcal{H}} := \{\est[\ket{\phi}] ~|~ \ket{\phi} \in \mathcal{H} \} \]
\[ E_S := \{\est[\ket{s}] ~|~ \ket{s} \in S \} \]
\[ f_{\min} := \min_{\ket{s} \in S} \mathcal{F}(\ket{s}, \est[\ket{s}]) \] 

and for all $\ket{\phi}$

\[ \mathcal{F}(\ket{\phi}, \est[\ket{\phi}]) = \max_{\ket{e} \in E_{\mathcal{H}}} \mathcal{F}(\ket{\phi}, \ket{e})\]

we know $E_S \subseteq E_{\mathcal{H}}$

\begin{align*} \mathcal{F}(\ket{\phi}, \est[\ket{\phi}]) &\ge \max_{\ket{s} \in S} \mathcal{F}(\ket{\phi}, \est[\ket{s}]) \\ &\ge \max_{\ket{s} \in S} \cos^2\Big( \arccos\sqrt{\mathcal{F} (\ket{\phi}, \ket{s})} + \arccos\sqrt{\mathcal{F}(\ket{s}, \est[\ket{s}])} \Big) 
\\ &\ge \max_{\ket{s} \in S} \cos^2\Big(\arccos\sqrt{\mathcal{F} (\ket{\phi}, \ket{s})} + \arccos{\sqrt{f_{\min}}}\Big)  
\\ &\ge \cos^2(\arccos\sqrt{d} + \arccos\sqrt{f_{\min}}) = (\sqrt{d}\sqrt{f_{\min}} - \sqrt{1-d}\sqrt{1-f_S})^2
\end{align*}

\section{Numerical Optimization}
\subsection{N-sector Subspace}
We know that $[H, S_{\text{total}}] = 0$ where $S_{\text{total}}$ is total spin operator. therefore, we can rewrite $H$ as a parameteric matrix in each N-sector subspace with basis $e_1 \dots e_m$

\[ H_{ij} = \mel{e_i}{H}{e_j} \]

And for the sake of simplicity we can assume ground state is $\ket{e_1}$

Now eq. \ref{eq:opt} as a parameteric optimization problem, can be solved approximately for any target state using gradient-descent method by a deep-learning framework. This approach is the same as what Innocenti. et. al. did for gate construction.

the result of solving eq. \ref{eq:opt} for a target state such as $\ket{\phi}$, will give us a Hamiltonian, therefore, we can define $\est[\ket{\phi}] = e^{iH^*t}$ and consequently MGF.

Note that due to randomness in initialization of this optimization method, which leads to sub-optimal results, we repeat the optimization for each target multiple times and report the best result.

\section{Results}
for reporting results, we define
\[ \bar{f} := \frac{\sum_{\ket{s}\in S} \mathcal{F}(\ket{s}, \est[\ket{s}])}{|S|}  \]

\begin{table}[H]
\[ \begin{array}{c|c|c|c|c||c}
\dim \mathcal{H} & |S| & d & \bar{f} & f_{\min} & \text{MGF} \\
\hline 2 & 2560 & 0.980 & 0.99995 & 0.996 & 0.959 \\
3 & 13734 & 0.955 & 0.99570 & 0.944 & 0.810 \\
4 & 22599 & 0.921 & 0.96058 & 0.621 & 0.340 \\
\end{array} \]
% TODO report errors
\caption{one-sector subspace}
\end{table}
\section*{Appendix}
proof of Lemma 1:

\begin{align*} \braket{f(v)}{f(v')} &= \sum_{i=1}^N f(v')_i^* f(v)_i = \sum_{i=1}^N (v_{2i} - iv_{2i+1}) (v'_{2i} + iv'_{2i+1}) \\
& = \sum_{i=1}^N v_{2i}v'_{2i} + v_{2i+1}v'_{2i+1} +  \sum_{i=1}^N i(v_{2i}v'_{2i+1} - v'_{2i}v_{2i+1}) \\
& = \va{v}\cdot\va{v'} + \sum_{i=1}^N i(v_{2i}v'_{2i+1} - v_{2i}v_{2i+1} + v_{2i}v_{2i+1}- v'_{2i}v_{2i+1}) \end{align*}

defining $I \in \mathbb{R}$ as
\[ \braket{f(v)}{f(v')} = \va{v}\cdot\va{v'} + iI \]
\begin{align*} \mathcal{F}(\ket{f(v)}, \ket{f(v')}) = |\braket{f(v)}{f(v')}| &= \sqrt{(\va{v}\cdot\va{v'})^2 + I^2} \\
& \ge \va{v}.\va{v'}
\end{align*}

\end{document}
