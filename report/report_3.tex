\documentclass{article}
\usepackage{comment}

\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}

%\usepackage{amsmath}
\usepackage[arrowdel]{physics}
\usepackage{amsfonts}
\usepackage{amsthm}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\est}{Est}
\def\ind{\hspace{\parindent}}
\title{Brief Report}
\author{Amirreza Negari, Amirhossein Estiri, Sajad Kahani}
\date{Augest 2019}
\begin{document}

\maketitle

\section{Optimization Problem}
let ${\lambda_1\dots\lambda_m}$ be set of free degrees of Hamiltonian, $\ket{\phi_0}$ the ground state and $\ket{\psi}$ the target state.

formally, the problem can be formulated by this equation
\[ H^*(\lambda_1\dots\lambda_m), t^* = \argmax_{\lambda_1..\lambda_m, t} \mathcal{F}(e^{iH(\lambda_1\dots\lambda_m)t} \ket{\phi_0}, \ket{\psi}) \]

where $\mathcal{F}(., .)$ is fidelity.

specifically, we are focusing on a Hisenberg model, therefore

\[ H(J_1\dots J_{N-1}, B_1\dots B_N) = \sum_{i=1}^{N-1} J_i X_i X_{i+1} + \sum_{i=1}^N B_i Z_i\]

In this case, by multiplying each degrees by $\alpha$, and dividing $t$ by $\alpha$ result remains the same, therefore we can substitute $t$ with $t_0$.

\begin{equation} 
\label{eq:opt}
H^*(J_1\dots J_{N-1}, B_1\dots B_N) = \argmax_{J_1\dots J_{N-1}, B_1\dots B_N} \mathcal{F}(e^{iHt_0} \ket{\phi_0}, \ket{\psi})
\end{equation}


\section{Minimum Guaranteed Fidelity}

for any method for estimating states (that estimates $\ket{\phi}$ with $\est[\ket{\phi}]$, we can define a ``minimum guaranteed fidelity" (MGF) that

\[ \mathcal{F}(\ket{\phi}, \est[\ket{\phi}]) \ge \text{MGF} \]

in order to find MGF empirically, 
we define a mapping $f: \mathbb{R}^{2N} \rightarrow \mathcal{H}$ with $\dim \mathcal{H} = N$ as 
\[ f(\va{v}) := \sum_{i=1}^N (v_{2i} + iv_{2i+1}) \ket{i}\]

\newtheorem{lemma}{Lemma}
\begin{lemma}
for two arbitrary vectors $\va{v}$ and $\va{v'}$ in $\mathbb{R}$
\[ \mathcal{F}(f(\va{v}), f(\va{v'})) \ge \va{v}\cdot\va{v'} \]
\end{lemma}

now we choose a set of $k$ equidistributed points on a 2N-d unit hypersphere called $S$.

for an arbitrary point $\va{x}$ on sphere, exists $\va{t} \in P$ that $\forall \va{p} \in P - \{\va{t}\} ~~ \va{t}\cdot\va{x} > \va{t}\cdot \va{p}$

then by mapping to hilbert space
\[ S := \{ f(\va{p}) ~|~ \va{p} \in P \} \]
\[ d := \min_{\va{x} \in P} ~\max_{\va{y} \in P - \{\va{x}\}} \va{x}\cdot\va{y} \]
\[ \forall \ket{\phi} \in \mathcal{H} ~~ \exists \ket{t} \in S ~~ \mathcal{F}(\ket{\phi}, \ket{t}) \ge d \]

\begin{lemma}
assume three arbitrary states $\ket{a},\ket{b},\ket{c}$

\[ \mathcal{F}(\ket{a},\ket{c}) \ge \mathcal{F}(\ket{a},\ket{b})\mathcal{F}(\ket{b},\ket{c})\]
\end{lemma}

holy shit, the lemma is wrong!

now defining these
\[ E_{\mathcal{H}} := \{\est[\ket{\phi}] ~|~ \ket{\phi} \in \mathcal{H} \} \]
\[ E_S := \{\est[\ket{s}] ~|~ \ket{s} \in S \} \]
\[ f_S := \min_{\ket{s} \in S} \mathcal{F}(\ket{s}, \est[\ket{s}]) \] 

and for all $\ket{\phi}$

\[ \mathcal{F}(\ket{\phi}, \est[\ket{\phi}]) = \max_{\ket{e} \in E_{\mathcal{H}}} \mathcal{F}(\ket{\phi}, \ket{e})\]

we know $E_S \subseteq E_{\mathcal{H}}$

\begin{align*} \mathcal{F}(\ket{\phi}, \est[\ket{\phi}]) &\ge \max_{\ket{s} \in S} \mathcal{F}(\ket{\phi}, \est[\ket{s}]) \\ &\ge \max_{\ket{s} \in S} \mathcal{F} (\ket{\phi}, \ket{s})\mathcal{F}(\ket{s}, \est[\ket{s}]) 
\\ &\ge \max_{\ket{s} \in S} \mathcal{F} (\ket{\phi}, \ket{s}) f_S  
\\ &\ge d ~ f_S
\end{align*}

\section{Numerical Optimization}
\subsection{One-sector Subspace}
For the sake of simplicity, we can assume ground state is $\ket{1}$%
\footnote{defining $\ket{i}$ as an state with $i$th qbit excited.}.

Eq. \ref{eq:opt} as a parameteric optimization problem, can be solved approximately for any target state using gradient-descent method by a deep-learning framework

This approach is the same as what Innocenti. et. al. did for gate construction.

the result of solving eq. \ref{eq:opt} for a target state such as $\ket{\phi}$, will give us a Hamiltonian, therefore, we can define $\est[\ket{\phi}] = e^{iH^*t}$ and consequently MGF

\section*{Appendix}
proof of Lemma 1:

\begin{align*} \braket{f(v)}{f(v')} &= \sum_{i=1}^N f(v')_i^* f(v)_i = \sum_{i=1}^N (v_{2i} - iv_{2i+1}) (v'_{2i} + iv'_{2i+1}) \\
& = \sum_{i=1}^N v_{2i}v'_{2i} + v_{2i+1}v'_{2i+1} +  \sum_{i=1}^N i(v_{2i}v'_{2i+1} - v'_{2i}v_{2i+1}) \\
& = \va{v}\cdot\va{v'} + \sum_{i=1}^N i(v_{2i}v'_{2i+1} - v_{2i}v_{2i+1} + v_{2i}v_{2i+1}- v'_{2i}v_{2i+1}) \end{align*}

defining $I \in \mathbb{R}$ as
\[ \braket{f(v)}{f(v')} = \va{v}\cdot\va{v'} + iI \]
\begin{align*} \mathcal{F}(\ket{f(v)}, \ket{f(v')}) = |\braket{f(v)}{f(v')}| &= \sqrt{(\va{v}\cdot\va{v'})^2 + I^2} \\
& \ge \va{v}.\va{v'}
\end{align*}

\end{document}
